#+AUTHOR: Gideon Dresdner
#+OPTIONS: toc:nil

* Imports
#+BEGIN_SRC ipython :session :exports none
  %matplotlib inline
  import matplotlib, numpy
  matplotlib.use('Agg')
  import matplotlib.pyplot as plt
  import scipy.io as sio
  import cv2
  import numpy as np
  import pandas as pd
  import sklearn.metrics
  import json
  import os
  import functools
  matplotlib.style.use('ggplot')
  CEDARS_SINAI_DIR = "/home/gideon/Data/cedars-sinai/"
  img_filename = CEDARS_SINAI_DIR + "TIFF color normalized sequential filenames/test%d.tif"
  raw_label_filename = CEDARS_SINAI_DIR + "ATmask sequential filenames/test%d_Mask.mat"
  with_annotations_filename = CEDARS_SINAI_DIR + "Color annotation sequential filenames/test%d_Annotated.tif"
  num_samples = 224
  BASEDIR = '/home/gideon/Data/tmrn-preds/'

  with open('train.txt') as exs:
      xtr = [int(x.strip()) for x in exs]

  with open('validation.txt') as exs:
      xval = [int(x.strip()) for x in exs]

  with open('test.txt') as exs:
      xte = [int(x.strip()) for x in exs]

  xval = [200, 77, 69, 169, 220, 171, 120, 163]      # TODO temp

  idx2tumor_grade = ['stroma', 'high grade', 'benign/normal glands', 'low grade']

  def directory(path):
      BASE_DIR = '~/Pictures/figures/tmrn/'
      dir = BASE_DIR + path
      if not os.path.exists(dir):
          os.makedirs(dir)
      return dir
#+END_SRC

#+RESULTS:
  
* Helper Functions

#+BEGIN_SRC ipython :session :exports none
  # N.B. duplicated code
  def center_pixel(patch):
      '''
      Takes a patch of pixel-wise labels and extracts the representative
      label, namely the center of the patch.
      '''
      length, height = patch.shape[:2]
      return np.array([patch[length/2, height/2]-1]) # labels are 0-indexed.

  def _patches(img, patch_size, stride):
      assert 2 <= len(img.shape) <= 3
      num_xpatches = int((img.shape[0]-patch_size+1) / stride)
      num_ypatches = int((img.shape[1]-patch_size+1) / stride)

      #blah
      ret = []
      for x in range(0, img.shape[0]-patch_size+1, stride):
          for y in range(0, img.shape[1]-patch_size+1, stride):
              ret.append(img[x : x+patch_size, y : y+patch_size])
      return ret

  def confusion_matrix(ytrue, ypreds, labels):
        return sklearn.metrics.confusion_matrix(ytrue, ypreds, labels=labels)

  def load_img(sample_num):
      return cv2.imread(img_filename %(sample_num))

  def load_preds(model, sample_num):
      return np.load(BASEDIR + '/%s/test%s_preds.npy' %(model, sample_num))

  def load_labels(sample_num):
      return sio.loadmat(raw_label_filename % sample_num)['ATmask']

  def load_log(model):
      with open(BASEDIR + '/%s.json' % model) as logfile:
          return json.load(logfile)

  def load_groundtruth(sample_num):
      return cv2.imread(with_annotations_filename % sample_num)

  @functools.lru_cache(maxsize=128)
  def confusion_matrix_for_model(model):
      log = load_log(model)
      ps = log['patch_size']

      # labels[63:-64, 63:-64]

      ypreds = []
      ytrue = []
      for sample_num in xval:
          preds = load_preds(model, sample_num)
          labels = load_labels(sample_num)
          center_labels = labels[ps/2-1:-ps/2, ps/2-1:-ps/2]
          center_labels = center_labels-1        # neural network labels are 0-indexed.

          ypreds.extend(preds)
          ytrue.extend(center_labels)

      return confusion_matrix(np.concatenate(ytrue),
                              np.concatenate(ypreds), labels=[0,1,2,3])

  def visualize_confusion_matrix(cm, title):
      cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]

      plt.imshow(cm_normalized, interpolation='nearest', cmap=plt.cm.Blues)
      plt.title(title)
      plt.colorbar()
      tick_marks = np.arange(4)
      plt.xticks(tick_marks, idx2tumor_grade, rotation=45)
      plt.yticks(tick_marks, idx2tumor_grade)
      plt.tight_layout()
      plt.ylabel('True label')
      plt.xlabel('Predicted label')

      return plt

  def plot_preds_vs_truth(model, sample_num):
      results = np.load(BASEDIR + '/%s/test%s_preds.npy' %(model, sample_num))

      plt.subplot(1,num_subplots,1)
      cm = matplotlib.colors.ListedColormap(['yellow', 'red', 'blue', 'green'])
      plt.imshow(results, cmap=cm)
      # plt.colorbar()
      plt.gca().set_xticklabels([])
      plt.title('Preds sample: %d' % sample_num)

      ax = plt.subplot(1,num_subplots,2)
      imgplot = plt.imshow(load_groundtruth(sample_num))
      assert imgplot != None
      plt.gca().set_xticklabels([])
      # plt.gca().set_yticklabels([])
      plt.title('Ground Truth')
#+END_SRC

#+RESULTS:
  
* Label Distribution 
#+BEGIN_SRC ipython :session :file /tmp/labelcounts.png :exports results
counts = []
for sample_num in xtr:
    labels = sio.loadmat(raw_label_filename % sample_num)['ATmask']
    labels = labels.flatten()
    label_counts = np.bincount(labels)[1:]
    label_counts = np.append(label_counts, np.array([0] * (4 - len(label_counts))))
    label_counts = label_counts / float(len(labels))
    counts.append(label_counts)

counts = np.array(counts)

df = pd.DataFrame(counts)
df.columns=[idx2tumor_grade]

plt.figure()
plt.suptitle('Label Counts')
plt.subplot(121)

plt.title('Training')
plt.ylabel('fraction of dataset')
df.mean().plot(kind='bar'); plt.axhline(0, color='k')

counts = []
for sample_num in xval:
    labels = sio.loadmat(raw_label_filename % sample_num)['ATmask']
    labels = labels.flatten()
    label_counts = np.bincount(labels)[1:]
    label_counts = np.append(label_counts, np.array([0] * (4 - len(label_counts))))
    label_counts = label_counts / float(len(labels))
    counts.append(label_counts)

counts = np.array(counts)

df = pd.DataFrame(counts)
df.columns=[idx2tumor_grade]

plt.subplot(122)

plt.title('Validation')
df.mean().plot(kind='bar'); plt.axhline(0, color='k')
#+end_src

#+RESULTS:
[[file:/tmp/labelcounts.png]]

* Benchmarks

#+begin_src ipython :session :exports results
    jpl_basedir = '/home/gideon/Data/jpl-cedars-sinai-results/'

    jpl_ypreds = []
    ytrue = []
    for sample_num in xte:
        true_labels = sio.loadmat(raw_label_filename % sample_num)['ATmask']
        jpl_results = cv2.imread(jpl_basedir + 'output_masks/test%d_Mask.png' % sample_num)
        assert jpl_results != None
        assert np.array_equal(jpl_results[:,:,0], jpl_results[:,:,1])
        assert np.array_equal(jpl_results[:,:,1], jpl_results[:,:,2])

        jpl_results = jpl_results[:,:,0]
        jpl_results[jpl_results == 60] = 1
        jpl_results[jpl_results == 120] = 2
        jpl_results[jpl_results == 180] = 3
        jpl_results[jpl_results == 240] = 4

        # | 1 | Y | stroma               |
        # | 2 | R | high grade           |
        # | 3 | B | benign/normal glands |
        # | 4 | G | low grade            |

        jpl_ypreds.append(jpl_results.flatten())
        ytrue.append(true_labels.flatten())
#+end_src

#+RESULTS:
  
#+BEGIN_SRC ipython :session :exports results :file /tmp/jpl_confusion.png
  try:
      jpl_cm
  except NameError:
      jpl_cm = sklearn.metrics.confusion_matrix(np.array(ytrue).flatten(), np.array(jpl_ypreds).flatten(), labels=[1,2,3,4])
  normalized_jpl_cm = jpl_cm.astype('float') / jpl_cm.sum(axis=1)[:, np.newaxis]
  visualize_confusion_matrix(normalized_jpl_cm, 'JPL Model')
#+END_SRC

# Sanity check for proper mapping of JPL png values to label values.
#+BEGIN_SRC ipython :session  :exports results :file /tmp/asdf.png :eval never
  sample_num = xte[3]
  true_labels = sio.loadmat(raw_label_filename % sample_num)['ATmask']
  jpl_results = cv2.imread(jpl_basedir + 'output_masks/test%d_Mask.png' % sample_num)
  jpl_results = jpl_results[:,:,0]
  jpl_results[jpl_results == 60] = 1
  jpl_results[jpl_results == 120] = 2
  jpl_results[jpl_results == 180] = 3
  jpl_results[jpl_results == 240] = 4
  plt.imshow(np.concatenate([jpl_results, np.zeros((1201,128)), true_labels], axis=1))
#+END_SRC
  
#+BEGIN_SRC ipython :session :exports results
"Validation Accuracy %.2f" % np.average(np.array(ytrue).flatten() == np.array(jpl_ypreds).flatten())
#+END_SRC

#+RESULTS:
: 'Validation Accuracy 0.81'

#+begin_src ipython :session :file /tmp/te13.png :exports results
  sample_num = 13
  raw_img = load_img(sample_num)
  assert raw_img != None
  labels = load_labels(sample_num)

  plt.figure()
  # plt.suptitle('Test Ex: ' + str(sample_num))

  num_subplots = 3

  plt.subplot(1,num_subplots,1)
  imgplot = plt.imshow(raw_img)
  plt.gca().set_xticklabels([])
  plt.title('Input image')

  ax = plt.subplot(1,num_subplots,2)
  imgplot = plt.imshow(cv2.imread(with_annotations_filename % sample_num))
  assert imgplot != None
  plt.gca().set_xticklabels([])
  plt.gca().set_yticklabels([])
  plt.title('Pathologist Label')

  plt.subplot(1,num_subplots,3)
  imgplot = plt.imshow(
      cv2.imread(jpl_basedir + 'output_masks/test%d_Mask.png' % sample_num))
  plt.gca().set_xticklabels([])
  plt.gca().set_yticklabels([])
  plt.title('JPL prediction')
#+end_src

#+RESULTS:
[[file:/tmp/te13.png]]

* Learning Curves
# TODO make sure the titles show up!!
#+begin_src ipython :session :file /tmp/aug_lr_curves.png :exports results
  augmentation_experiments = ['rotation.json',  'flip.json', 'no_augmentation.json', 'flip_rot.json']
  train_accs = []
  for expfilename in augmentation_experiments:
      with open(BASEDIR + expfilename) as json_data:
          experiment = json.load(json_data)
          train_accs.append(experiment['train_accs'])

  shortest = min([len(l) for l in train_accs])
  train_accs = [l[:shortest] for l in train_accs]

  foo = []
  for l in train_accs:
      asdf = []
      for x,y in l:
          asdf.append(float(y))
      foo.append(asdf)

  augexpersdf = pd.DataFrame(np.array(foo).transpose(), columns = ['rotation', 'flip', 'no augmentation', 'flip and rotation'])
  pd.ewma(augexpersdf, halflife=0.9999).plot()

  plt.figure(figsize=(40,40))
  plt.title('Training Curves for Data Augmentation (10 Layers Bottleneck)')
  plt.xlabel('Iteration')
  plt.ylabel('Accuracy')
  plt.ylim([0, 1])
#+end_src

#+RESULTS:
[[file:/tmp/aug_lr_curves.png]]

#+BEGIN_SRC ipython :session :file /tmp/depth_lr_curves.png :exports results
  depth_experiments = ['4layers_couple.json', '6layers_couple.json', '18_layers_couple.json']
  train_accs = []
  for depth_expr in depth_experiments:
      with open(BASEDIR + depth_expr) as json_data:
          experiment = json.load(json_data)
          train_accs.append(experiment['train_accs'])

  shortest = min([len(l) for l in train_accs])
  train_accs = [l[:shortest] for l in train_accs]

  foo = []
  for l in train_accs:
      asdf = []
      for x,y in l:
          asdf.append(float(y))
      foo.append(asdf)

  depthexprdf = pd.DataFrame(np.array(foo).transpose(), columns=['4 layers', '6 layers', '18 layers'])
  pd.ewma(depthexprdf, halflife=0.9999).plot()

  plt.figure(figsize=(40,40))
  plt.title('Training Curves for Networks of Different Depths (Couples)')
  plt.xlabel('Iteration')
  plt.ylabel('Accuracy')
  plt.ylim([0, 1])
#+END_SRC

#+RESULTS:
[[file:/tmp/depth_lr_curves.png]]

** Patch Size Experiments

In these experiments I hold the NN architecture fixed at 4 layers: one
Conv7x7 initial layer, two internal Conv3x3 layers and a final layer
wired up to the outputs (all 4 labels). (Duplicated in the CM section).

#+BEGIN_SRC ipython :session :exports none
  #@functools.lru_cache(maxsize=128)
  def simple_plot_tr_accs(experiment_name, title):
      log = load_log(experiment_name)
      tr_accs = log['train_accs']
      tr_accs = np.array(tr_accs)[:,1]
      tr_accs.astype('float')
      df = pd.DataFrame(tr_accs)
      plot = pd.ewma(df, halflife=0.9999).plot()
      plt.title(title)
      plt.xlabel('iteration num')
      plt.ylabel('accuracy')
      return plot
#+END_SRC

#+RESULTS:

#+BEGIN_SRC ipython :session :file /tmp/ps16_learning_curve.png :exports results
simple_plot_tr_accs('ps16', 'Patch Size 16')
#+END_SRC

#+RESULTS:
[[file:/tmp/ps16_learning_curve.png]]

#+BEGIN_SRC ipython :session :file /tmp/ps32_learning_curve.png :exports results
simple_plot_tr_accs('ps32', 'Patch Size 32')
#+END_SRC

#+RESULTS:
[[file:/tmp/ps32_learning_curve.png]]

#+BEGIN_SRC ipython :session :file /tmp/ps64_learning_curve.png :exports results
simple_plot_tr_accs('ps64', 'Patch Size 64')
#+END_SRC

#+RESULTS:
[[file:/tmp/ps64_learning_curve.png]]

#+BEGIN_SRC ipython :session :file /tmp/ps128_learning_curve.png :exports results
simple_plot_tr_accs('ps128', 'Patch Size 128')
#+END_SRC

#+RESULTS:
[[file:/tmp/ps128_learning_curve.png]]

* Validation Results (CM and Accuracies)

#+BEGIN_SRC ipython :session :file /tmp/model_accuracies.png :exports results
  def model_accuracy(model):
      accs = []
      for sample_num in xval:
          preds = np.load(BASEDIR + '/%s/test%s_preds.npy' %(model, sample_num))

          labels = sio.loadmat(raw_label_filename % sample_num)['ATmask']
          center_labels = labels[63:-64, 63:-64] # TODO hard coded patch size
          center_labels = center_labels-1        # neural network labels are 0-indexed.

          accs.append(np.average((preds == center_labels).flatten()))

      return accs

  model_names = ['4layers_couple', '6layers_couple', 'flip_rot']
  df = pd.DataFrame(dict((m, model_accuracy(m)) for m in model_names))
  df.mean().plot(kind='bar'); plt.axhline(0, color='k'); plt.ylabel('validation accuracy')
#+END_SRC

#+RESULTS:
[[file:/tmp/model_accuracies.png]]

#+BEGIN_SRC ipython :session :exports results :file /tmp/confusion_matrix_4layers_couple.png
  cm = confusion_matrix_for_model('4layers_couple')
  visualize_confusion_matrix(cm, '4 Layers Couple Arch')
#+END_SRC

#+RESULTS:
[[file:/tmp/confusion_matrix_4layers_couple.png]]

#+BEGIN_SRC ipython :session :exports results :file /tmp/confusion_matrix_6layers_couple.png
  cm = confusion_matrix_for_model('6layers_couple')
  visualize_confusion_matrix(cm, '6 Layers Couple Arch')
#+END_SRC

#+RESULTS:
# [[file:/tmp/confusion_matrix_6layers_couple.png]]

#+BEGIN_SRC ipython :session :exports results :file /tmp/confusion_matrix_10layers_withaug.png
  cm = confusion_matrix_for_model('flip_rot')
  visualize_confusion_matrix(cm, '10 Layers With Flipping and Rotations')
#+END_SRC

** Patch Size Experiments

In these experiments I hold the NN architecture fixed at 4 layers: one
Conv7x7 initial layer, two internal Conv3x3 layers and a final layer
wired up to the outputs (all 4 labels).

#+RESULTS:
[[file:/tmp/confusion_matrix_10layers_withaug.png]]

#+BEGIN_SRC ipython :session :exports results :file /tmp/ps16.png
  cm = confusion_matrix_for_model('ps16')
  visualize_confusion_matrix(cm, 'Patch Size 16')
#+END_SRC

#+RESULTS:
[[file:/tmp/ps16.png]]

#+BEGIN_SRC ipython :session :exports results :file /tmp/ps32.png
  cm = confusion_matrix_for_model('ps32')
  visualize_confusion_matrix(cm, 'Patch Size 32')
#+END_SRC

#+RESULTS:
[[file:/tmp/ps32.png]]

#+BEGIN_SRC ipython :session :exports results :file /tmp/ps64.png
  cm = confusion_matrix_for_model('ps64')
  visualize_confusion_matrix(cm, 'Patch Size 64')
#+END_SRC

#+RESULTS:
[[file:/tmp/ps64.png]]

#+BEGIN_SRC ipython :session :exports results :file /tmp/ps128.png
  cm = confusion_matrix_for_model('ps128')
  visualize_confusion_matrix(cm, 'Patch Size 128')
#+END_SRC

#+RESULTS:
[[file:/tmp/ps128.png]]



# #+BEGIN_SRC ipython :session :exports none :eval never
# # TODO refactor
#   for sample_num in xval:
#       model = '4layers_couple'
#       results = np.load(BASEDIR + '/%s/test%s_preds.npy' %(model, sample_num))

#       plt.subplot(1,num_subplots,1)
#       cm = matplotlib.colors.ListedColormap(['yellow', 'red', 'blue', 'green'])
#       plt.imshow(results, cmap=cm)
#       # plt.colorbar()
#       plt.gca().set_xticklabels([])
#       plt.title('Sample %d' % sample_num)

#       ax = plt.subplot(1,num_subplots,2)
#       imgplot = plt.imshow(cv2.imread(with_annotations_filename % sample_num))
#       assert imgplot != None
#       plt.gca().set_xticklabels([])
#       # plt.gca().set_yticklabels([])
#       plt.title('Pathologist Label')
#       plt.savefig('/tmp/results_%s_test%s.png' %(model, str(sample_num)),
#                   bbox_inches='tight')
# #+END_SRC

# * 4 Layer Couple Architecture Validation Set

# [[/tmp/results_4layers_couple_test101.png]]

# [[/tmp/results_4layers_couple_test102.png]]

# [[/tmp/results_4layers_couple_test107.png]]

# [[/tmp/results_4layers_couple_test120.png]]

# [[/tmp/results_4layers_couple_test122.png]]

# [[/tmp/results_4layers_couple_test125.png]]

# [[/tmp/results_4layers_couple_test151.png]]

# [[/tmp/results_4layers_couple_test157.png]]

# [[/tmp/results_4layers_couple_test163.png]]

# [[/tmp/results_4layers_couple_test169.png]]

# [[/tmp/results_4layers_couple_test170.png]]

# [[/tmp/results_4layers_couple_test171.png]]

# [[/tmp/results_4layers_couple_test199.png]]

# [[/tmp/results_4layers_couple_test200.png]]

# [[/tmp/results_4layers_couple_test204.png]]

# [[/tmp/results_4layers_couple_test207.png]]

# [[/tmp/results_4layers_couple_test220.png]]

# [[/tmp/results_4layers_couple_test36.png]]

# [[/tmp/results_4layers_couple_test48.png]]

# [[/tmp/results_4layers_couple_test53.png]]

# [[/tmp/results_4layers_couple_test61.png]]

# [[/tmp/results_4layers_couple_test69.png]]

# [[/tmp/results_4layers_couple_test75.png]]

# [[/tmp/results_4layers_couple_test77.png]]

# [[/tmp/results_4layers_couple_test89.png]]
# * 6 Layer Couple Architecture Validation Set
# #+BEGIN_SRC ipython :session :exports none :eval never
#   for sample_num in xval:
#       model = '6layers_couple'
#       results = np.load('/tmp/%s/test%s_preds.npy' %(model, sample_num))

#       plt.subplot(1,num_subplots,1)
#       cm = matplotlib.colors.ListedColormap(['yellow', 'red', 'blue', 'green'])
#       plt.imshow(results, cmap=cm)
#       # plt.colorbar()
#       plt.gca().set_xticklabels([])
#       plt.title('Sample %d' % sample_num)

#       ax = plt.subplot(1,num_subplots,2)
#       imgplot = plt.imshow(cv2.imread(with_annotations_filename % sample_num))
#       assert imgplot != None
#       plt.gca().set_xticklabels([])
#       # plt.gca().set_yticklabels([])
#       plt.title('Pathologist Label')
#       plt.savefig('/tmp/results_%s_test%s.png' %(model, str(sample_num)),
#                   bbox_inches='tight')
# #+END_SRC

# #+RESULTS:
# : <matplotlib.figure.Figure at 0x7fcc2b234c50>

# [[/tmp/results_6layers_couple_test101.png]]

# [[/tmp/results_6layers_couple_test102.png]]

# [[/tmp/results_6layers_couple_test107.png]]

# [[/tmp/results_6layers_couple_test120.png]]

# [[/tmp/results_6layers_couple_test122.png]]

# [[/tmp/results_6layers_couple_test125.png]]

# [[/tmp/results_6layers_couple_test151.png]]

# [[/tmp/results_6layers_couple_test157.png]]

# [[/tmp/results_6layers_couple_test163.png]]

# [[/tmp/results_6layers_couple_test169.png]]

# [[/tmp/results_6layers_couple_test170.png]]

# [[/tmp/results_6layers_couple_test171.png]]

# [[/tmp/results_6layers_couple_test199.png]]

# [[/tmp/results_6layers_couple_test200.png]]

# [[/tmp/results_6layers_couple_test204.png]]

# [[/tmp/results_6layers_couple_test207.png]]

# [[/tmp/results_6layers_couple_test220.png]]

# [[/tmp/results_6layers_couple_test36.png]]

# [[/tmp/results_6layers_couple_test48.png]]

# [[/tmp/results_6layers_couple_test53.png]]

# [[/tmp/results_6layers_couple_test61.png]]

# [[/tmp/results_6layers_couple_test69.png]]

# [[/tmp/results_6layers_couple_test75.png]]

# [[/tmp/results_6layers_couple_test77.png]]

# [[/tmp/results_6layers_couple_test89.png]]

# * 10 Layer Bottle Neck With Data Flipping and Rotation
# #+BEGIN_SRC ipython :session :exports none
#   for sample_num in xval:
#       model = 'flip_rot'
#       results = np.load('/tmp/%s/test%s_preds.npy' %(model, sample_num))

#       plt.subplot(1,num_subplots,1)
#       cm = matplotlib.colors.ListedColormap(['yellow', 'red', 'blue', 'green'])
#       plt.imshow(results, cmap=cm)
#       # plt.colorbar()
#       plt.gca().set_xticklabels([])
#       plt.title('Sample %d' % sample_num)

#       ax = plt.subplot(1,num_subplots,2)
#       imgplot = plt.imshow(cv2.imread(with_annotations_filename % sample_num))
#       assert imgplot != None
#       plt.gca().set_xticklabels([])
#       # plt.gca().set_yticklabels([])
#       plt.title('Pathologist Label')
#       plt.savefig('/tmp/results_%s_test%s.png' %(model, str(sample_num)),
#                   bbox_inches='tight')
# #+END_SRC

# #+RESULTS:
# : <matplotlib.figure.Figure at 0x7fcc2afda5f8>

# [[/tmp/results_flip_rot_test101.png]]

# [[/tmp/results_flip_rot_test102.png]]

# [[/tmp/results_flip_rot_test107.png]]

# [[/tmp/results_flip_rot_test120.png]]

# [[/tmp/results_flip_rot_test122.png]]

# [[/tmp/results_flip_rot_test125.png]]

# [[/tmp/results_flip_rot_test151.png]]

# [[/tmp/results_flip_rot_test157.png]]

# [[/tmp/results_flip_rot_test163.png]]

# [[/tmp/results_flip_rot_test169.png]]

# [[/tmp/results_flip_rot_test170.png]]

# [[/tmp/results_flip_rot_test171.png]]

# [[/tmp/results_flip_rot_test199.png]]

# [[/tmp/results_flip_rot_test200.png]]

# [[/tmp/results_flip_rot_test204.png]]

# [[/tmp/results_flip_rot_test207.png]]

# [[/tmp/results_flip_rot_test220.png]]

# [[/tmp/results_flip_rot_test36.png]]

# [[/tmp/results_flip_rot_test48.png]]

# [[/tmp/results_flip_rot_test53.png]]

# [[/tmp/results_flip_rot_test61.png]]

# [[/tmp/results_flip_rot_test69.png]]

# [[/tmp/results_flip_rot_test75.png]]

# [[/tmp/results_flip_rot_test77.png]]

# [[/tmp/results_flip_rot_test89.png]]

# #+BEGIN_SRC ipython :session :exports results :file /tmp/asdf.png
#   plot_preds_vs_truth('flip_rot', 169)
# #+END_SRC

# #+RESULTS:
# [[file:/tmp/asdf.png]]

